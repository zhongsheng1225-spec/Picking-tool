import streamlit as st
import pdfplumber
import pandas as pd
import re
import io
import os

st.set_page_config(page_title="è°ƒè¯•ç‰ˆ-æ‹£è´§å·¥å…·", layout="wide")

# --- æ™ºèƒ½åŠ è½½å‡½æ•° ---
def load_local_data(file_name):
    if not os.path.exists(file_name):
        return None
    try:
        # å°è¯•å¤šç§è¯»å–æ–¹å¼
        try: return pd.read_excel(file_name)
        except: pass
        try: return pd.read_csv(file_name, encoding='utf-8-sig')
        except: return pd.read_csv(file_name, encoding='gbk')
    except Exception as e:
        st.error(f"è¯»å– {file_name} å¤±è´¥: {e}")
        return None

df_prod = load_local_data("product_info.csv")
df_label = load_local_data("label_info.csv")

st.title("ğŸ“‹ æ‹£è´§å•è‡ªåŠ¨æå– (æ•°æ®åŒ¹é…é¢„è§ˆ)")

# ä¾§è¾¹æ å®æ—¶è¯Šæ–­
with st.sidebar:
    st.header("ğŸ” æ•°æ®è¯Šæ–­")
    if df_prod is not None:
        st.success(f"å•†å“è¡¨: å·²åŠ è½½ {len(df_prod)} è¡Œ")
        st.write("åˆ—å:", list(df_prod.columns)) # æ˜¾ç¤ºè¡¨å¤´ï¼Œæ–¹ä¾¿å¯¹é½
    else:
        st.error("æœªæ‰¾åˆ° product_info.csv")
        
    if df_label is not None:
        st.success(f"æ ‡ç­¾è¡¨: å·²åŠ è½½ {len(df_label)} è¡Œ")
        st.write("åˆ—å:", list(df_label.columns))
    else:
        st.error("æœªæ‰¾åˆ° label_info.csv")

uploaded_pdf = st.file_uploader("ä¸Šä¼  PDF æ‹£è´§å•", type="pdf")

if uploaded_pdf is not None:
    results = []
    with pdfplumber.open(uploaded_pdf) as pdf:
        for page in pdf.pages:
            text = page.extract_text() or ""
            wh_match = re.search(r"æ”¶è´§ä»“[:ï¼š]\s*([^\s\n]+)", text)
            current_wh = wh_match.group(1) if wh_match else "æœªçŸ¥"
            
            table = page.extract_table()
            if table:
                headers = table[0]
                try:
                    # åŠ¨æ€åŒ¹é… PDF çš„åˆ—
                    skc_text_idx = next(i for i, h in enumerate(headers) if h and 'å•†å“ä¿¡æ¯' in h)
                    sku_idx = next(i for i, h in enumerate(headers) if h and 'SKUè´§å·' in h)
                    qty_idx = next(i for i, h in enumerate(headers) if h and 'å®é™…å‘è´§æ•°' in h)
                    
                    for row in table[1:]:
                        if not row[sku_idx] or "åˆè®¡" in str(row): continue
                        
                        sku = str(row[sku_idx]).strip().replace('\n', '')
                        qty = str(row[qty_idx]).strip()
                        
                        # æå– SKC
                        skc_id = ""
                        skc_match = re.search(r"SKC:\s*(\d+)", str(row[skc_text_idx]))
                        if skc_match: skc_id = skc_match.group(1)

                        # å…³è”åç§°
                        p_name = "-"
                        if df_prod is not None:
                            # å¼ºåˆ¶è½¬ä¸ºå­—ç¬¦ä¸²åŒ¹é…
                            m = df_prod[df_prod['å•†å“ç¼–ç '].astype(str).str.strip() == sku]
                            if not m.empty: p_name = m.iloc[0]['å•†å“åç§°']

                        # å…³è”æ ‡ç­¾
                        l_type = "-"
                        if df_label is not None and skc_id:
                            m = df_label[df_label['SKC ID'].astype(str).str.strip() == skc_id]
                            if not m.empty: l_type = m.iloc[0]['å›æ”¶æ ‡ç­¾']

                        results.append({
                            "å‘è´§ä»“åº“": current_wh,
                            "SKC ID": skc_id,
                            "å›æ”¶æ ‡ç­¾ç±»åˆ«": l_type,
                            "è´§å“ç¼–ç ": sku,
                            "å•†å“åç§°": p_name,
                            "å‘è´§æ•°é‡": qty
                        })
                except Exception: continue

    if results:
        df_res = pd.DataFrame(results)
        st.dataframe(df_res, use_container_width=True)
        
        # å¯¼å‡ºç»“æœ
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            df_res.to_excel(writer, index=False)
        st.download_button("ğŸ“¥ ä¸‹è½½ Excel", output.getvalue(), "result.xlsx")
